import streamlit as st
import numpy as np
import pandas as pd
import cv2
from skimage import measure, segmentation, feature

try:
    from sklearn.linear_model import LogisticRegression
    SKLEARN_OK = True
except Exception:
    LogisticRegression = None
    SKLEARN_OK = False

st.set_page_config(page_title="ç±³å“è³ªåˆ¤å®šAI.Shinshu-U R.Y.", layout="wide")
st.title("ç±³å“è³ªåˆ¤å®šAIã€€Shinshu Univ. R.Y.")


#ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
with st.expander("ğŸ“– ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰", expanded=False):
    st.markdown("""
**ç›®çš„**ï¼šé’ã„æ ã²ã¨ã¤ã«ç±³ç²’ãŒã¡ã‚‡ã†ã©ä¸€ç²’åã¾ã‚‹ã‚ˆã†ã«èª¿æ•´ã™ã‚‹ã€‚

**ãŠã™ã™ã‚é †ï¼š**  
1ï¼‰èƒŒæ™¯ã‚’æ­£ã—ãè¨­å®š â†’  
2ï¼‰äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆã§è¼ªéƒ­èª¿æ•´ â†’  
3ï¼‰ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦ / ãƒ”ãƒ¼ã‚¯é–“éš” + åˆ†é›¢ã®å¼·ã• ã§ã€Œ1ç²’=1ä¸­å¿ƒç‚¹ã€ â†’  
4ï¼‰æœ€å°/æœ€å¤§ç²’é¢ç©ã§å¤–ã‚Œå€¤ã‚«ãƒƒãƒˆ

---

### 1) æ˜ã‚‹ã„èƒŒæ™¯
- ç™½ã„ç´™ãƒ»ãƒ©ã‚¤ãƒˆãƒœãƒƒã‚¯ã‚¹ã§æ’®å½± â†’ **ãƒã‚§ãƒƒã‚¯**  
- é»’ã„å°ãƒ»æš—ã„èƒŒæ™¯ â†’ **ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™**  
â€» ã“ã“ãŒé•ã†ã¨ä»–ã®èª¿æ•´ãŒåŠ¹ãã«ãã„ã§ã™ã€‚

### 2) äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆ
- ç›®çš„ï¼šç±³ç²’ã® **è¼ªéƒ­ã®å¤ªã•** ã‚’å¾®èª¿æ•´  
- å‹•ã‹ã—æ–¹ï¼š**Â±5ã€œ15** ã‚’å°‘ã—ãšã¤  
- ç™½èƒŒæ™¯ï¼**ã‚ªãƒ³**ï¼š**ï¼‹ã§å¤ªã**ï¼**âˆ’ã§ç´°ã**  
- ç™½èƒŒæ™¯ï¼**ã‚ªãƒ•**ï¼š**ï¼‹ã§ç´°ã**ï¼**âˆ’ã§å¤ªã**  
- å›°ã£ãŸã‚‰ï¼š**æ¬ ã‘ã‚‹ â†’ âˆ’å´**ï¼**ã«ã˜ã‚€ â†’ ï¼‹å´**

### 3) ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦
- æ„å‘³ï¼šç²’ã‚’ **1ã¤ã¨ã—ã¦æ•°ãˆã‚‹å³ã—ã•**ï¼ˆé«˜ã„ã»ã©å³ã—ã„ï¼‰  
- å€¤â†‘ â†’ ã¾ã¨ã¾ã‚Šã‚„ã™ã„ï¼ˆåˆ†å‰²ãŒæ¸›ã‚‹ï¼‰ï¼ å€¤â†“ â†’ å‰²ã‚Œã‚„ã™ã„ï¼ˆéåˆ†å‰²ï¼‰  
- ç›®å®‰ï¼š**4ã€œ10**ï¼ˆç”»é¢ã§è¦‹ãŸç±³ç²’ã®**çŸ­ã„è¾ºã®åŠåˆ†**ãã‚‰ã„ï¼‰

### 4) ãƒ”ãƒ¼ã‚¯é–“éš”
- æ„å‘³ï¼šç²’ã® **ä¸­å¿ƒç‚¹ã©ã†ã—ã®æœ€å°è·é›¢**  
- å€¤â†‘ â†’ è¿‘ã„ç²’ãŒ 1 ã¤ã«è¦‹ãˆã‚„ã™ã„ ï¼ å€¤â†“ â†’ éåˆ†å‰²ã«ãªã‚Šã‚„ã™ã„  
- ç›®å®‰ï¼š**5ã€œ12**ï¼ˆ**çŸ­å¾„ã¨åŒç¨‹åº¦ã€œã‚„ã‚„å°ã•ã‚**ï¼‰

### 5) æœ€å°ç²’é¢ç©
- æ„å‘³ï¼šã“ã®é¢ç© **æœªæº€** ã¯ **ã‚´ãƒŸ** ã¨ã—ã¦é™¤å»  
- ç›®å®‰ï¼š**50ã€œ200**ï¼ˆâ†‘ã§ãƒã‚¤ã‚ºã«å¼·ã„ãŒå°ç²’ã‚‚æ¶ˆãˆã‚„ã™ã„ï¼‰

### 6) æœ€å¤§ç²’é¢ç©
- æ„å‘³ï¼šã“ã®é¢ç© **è¶…ãˆ** ã¯ **å¤§ãã™ãã‚‹å¡Š** ã¨ã—ã¦é™¤å¤–  
- ç›®å®‰ï¼š**1500ã€œ5000**ï¼ˆè§£åƒåº¦ã«ä¾å­˜ã€‚â†“ã§é€£çµå¡Šã‚’å¼¾ãã‚„ã™ã„ï¼‰

### 7) åˆ†é›¢ã®å¼·ã•
- æ„å‘³ï¼šãã£ã¤ã„ãŸç²’ã‚’ã©ã®ç¨‹åº¦å¼·åˆ¶çš„ã«åˆ†ã‘ã‚‹ã‹ã€‚
- å€¤â†‘ â†’ å¼·ãåˆ†é›¢ï¼ˆãã£ã¤ãã‚’å‰¥ãŒã—ã‚„ã™ã„ãŒï¼Œå°ç²’ãŒæ¬ ã‘ã‚„ã™ã„ï¼‰
- å€¤â†“ â†’ åˆ†é›¢ã¯å¼±ã„ï¼ˆç²’ãŒæ®‹ã‚Šã‚„ã™ã„ãŒï¼Œå¯†é›†éƒ¨åˆ†ã¯ä¸€å¡Šã«è¦‹ãˆã‚„ã™ã„ï¼‰
- ç›®å®‰ï¼š0ã€œ2 å›ç¨‹åº¦ã€‚ç”»åƒã®é‡ãªã‚Šå…·åˆã«ã‚ˆã£ã¦èª¿æ•´ã€‚

---

### æ—©è¦‹è¡¨
- å°ç²’ã‚„ã‚´ãƒŸã¾ã§æ•°ãˆã‚‹ â†’ **æœ€å°é¢ç©â†‘ / ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦â†‘**  
- è¿‘ã„ç²’ãŒ 1 ã¤ã«ãã£ã¤ã â†’ **ãƒ”ãƒ¼ã‚¯é–“éš”â†“ / ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦â†“**  
- è¼ªéƒ­ãŒæ¬ ã‘ã‚‹/ã‚®ã‚¶ã‚®ã‚¶ â†’ **äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆ âˆ’å´**  
- å¤ªã£ã¦é‡ãªã£ã¦è¦‹ãˆã‚‹ â†’ **äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆ ï¼‹å´**

### åˆæœŸã®ç›®å®‰
- äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼š**Â±10 å‰å¾Œ**  
- ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦ï¼š**6** ï¼ ãƒ”ãƒ¼ã‚¯é–“éš”ï¼š**8**  
- æœ€å°ç²’é¢ç©ï¼š**100** ï¼ æœ€å¤§ç²’é¢ç©ï¼š**3000**  
- åˆ†é›¢ã®å¼·ã•ï¼š1ï¼ˆ0ã€œ2 ã®ç¯„å›²ã§èª¿æ•´ï¼‰
- èƒŒæ™¯ã¯æ’®å½±æ¡ä»¶ã«åˆã‚ã›ã¦ã‚ªãƒ³/ã‚ªãƒ•

---

### â­ æœ€å¾Œã« 
è¨­å®šãŒæ•´ã„ã€**1æ =1ç²’**ã€ã«è¿‘ã¥ã„ãŸã‚‰ã€ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ã€**â‘ å­¦ç¿’** ã‚’æŠ¼ã—ã€å­¦ç¿’å®Œäº†å¾Œã« **â‘¡åˆ¤å®š** ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚
""")




#æ˜¾ç¤ºå°ºå¯¸
W_COL    = 360   # ç¬¬ä¸€è¡Œ
W_RESULT = 900   # ç¬¬äºŒè¡Œ

#èœå•
with st.sidebar:
    st.markdown("### èª¿æ•´ â†’ å­¦ç¿’ â†’ åˆ¤å®š")
    bg_bright = st.checkbox("æ˜ã‚‹ã„èƒŒæ™¯", value=False)
    th_offset = st.slider("äºŒå€¤åŒ–ã‚ªãƒ•ã‚»ãƒƒãƒˆ", -40, 40, 0)
    peak_min  = st.slider("ãƒ”ãƒ¼ã‚¯æ„Ÿåº¦", 2, 20, 5)
    peak_gap  = st.slider("ãƒ”ãƒ¼ã‚¯é–“éš”", 2, 20, 6)
    min_area  = st.slider("æœ€å°ç²’é¢ç©", 20, 600, 80, step=10)
    max_area  = st.slider("æœ€å¤§ç²’é¢ç©", 300, 8000, 3000, step=50)
    open_iter = st.slider("åˆ†é›¢ã®å¼·ã•", 0, 3, 1)
    st.markdown("---")

    ml_mode = st.selectbox(
        "å­¦ç¿’æ–¹æ³•",
        ["ã—ãã„å€¤ã®ã¿", "Logistic", "CNN"],
        index=0,
        help="å‚ç…§ç”»åƒã‹ã‚‰å­¦ç¿’ã—ã¦åˆ†é¡ã€‚Logistic=ç·šå½¢åˆ†é¡ã€CNN=å°å‹ç•³ã¿è¾¼ã¿ãƒãƒƒãƒˆ"
    )
    learn_btn = st.button("â‘  å­¦ç¿’")
    judge_btn = st.button("â‘¡ åˆ¤å®š")



#ä¸Šä¼ 
c1, c2, c3 = st.columns(3)
with c1:
    st.subheader("â‘  å¥åº·ç²’ï¼ˆå­¦ç¿’ç”¨ï¼‰")
    healthy_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»åŒæ¡ä»¶ã§æ’®å½±ã—ãŸç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„", type=["jpg","jpeg","png"], key="healthy")
with c2:
    st.subheader("â‘¡ ç™½æœªç†Ÿï¼ˆå­¦ç¿’ç”¨ï¼‰")
    white_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»åŒæ¡ä»¶ã§æ’®å½±ã—ãŸç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„", type=["jpg","jpeg","png"], key="white")
with c3:
    st.subheader("â‘¢ åˆ¤å®šå¯¾è±¡")
    target_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»åŒæ¡ä»¶ã§æ’®å½±ã—ãŸç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„", type=["jpg","jpeg","png"], key="target")

#å…±é€šå‡½æ•°
def read_bgr(uploaded):
    data = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
    return cv2.imdecode(data, cv2.IMREAD_COLOR)

def preprocess(img_bgr, bg_bright, th_offset, peak_min, peak_gap, min_area, max_area, open_iter):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    gray = cv2.GaussianBlur(gray, (3,3), 0)

    ret, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    thr = int(np.clip(ret + th_offset, 0, 255))
    mode = cv2.THRESH_BINARY_INV if bg_bright else cv2.THRESH_BINARY
    _, bw = cv2.threshold(gray, thr, 255, mode)
    bw = (bw > 0).astype(np.uint8)

    k3 = np.ones((3,3), np.uint8)
    if open_iter > 0:
        bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, k3, iterations=int(open_iter))
    else:
        bw = cv2.erode(bw, k3, 1); bw = cv2.dilate(bw, k3, 2); bw = cv2.erode(bw, k3, 1)

    dist = cv2.distanceTransform(bw, cv2.DIST_L2, 5)
    peaks = feature.peak_local_max(dist, min_distance=max(1,int(peak_gap)),
                                   threshold_abs=float(peak_min), labels=bw)
    if len(peaks) < 3:
        peaks = feature.peak_local_max(dist, min_distance=max(1,int(max(1,peak_gap//2))), labels=bw)

    markers = np.zeros_like(bw, np.int32)
    for i,(y,x) in enumerate(peaks,1): markers[y,x] = i
    if markers.max() == 0:
        labels = measure.label(bw, connectivity=2)
    else:
        labels = segmentation.watershed(-dist, markers=markers, mask=bw)

    comps = []
    for p in measure.regionprops(labels):
        a = int(p.area)
        if a < min_area or a > max_area: continue
        minr, minc, maxr, maxc = p.bbox
        comps.append({"area": a, "bbox": (int(minc), int(minr), int(maxc), int(maxr)), "coords": p.coords})
    return bw*255, comps

def whiteness_score(img_bgr, comp):
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)
    s = hsv[:,:,1]/255.0; v = hsv[:,:,2]/255.0
    yy, xx = comp["coords"][:,0], comp["coords"][:,1]
    vals = v[yy,xx] - 0.7*s[yy,xx]
    return float(vals.mean()) if vals.size else 0.0


#å°è´´å›¾
def crop_patch(img_bgr, comp, size=48):
    x1,y1,x2,y2 = comp["bbox"]
    x1 = max(0, x1); y1 = max(0, y1)
    x2 = min(img_bgr.shape[1]-1, x2); y2 = min(img_bgr.shape[0]-1, y2)
    crop = img_bgr[y1:y2+1, x1:x2+1]
    if crop.size == 0:  # å…œåº•
        return np.zeros((size, size, 3), dtype=np.uint8)
    return cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)

#CNN
import tensorflow as tf

def build_tiny_cnn(input_size=48):
    m = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_size, input_size, 3)),
        tf.keras.layers.Rescaling(1/255.0),
        tf.keras.layers.Conv2D(16, 3, padding="same", activation="relu"),
        tf.keras.layers.MaxPool2D(),
        tf.keras.layers.Conv2D(32, 3, padding="same", activation="relu"),
        tf.keras.layers.MaxPool2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation="relu"),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(1, activation="sigmoid")  # 1=ç™½æœªç†Ÿ
    ])
    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
              loss="binary_crossentropy", metrics=["accuracy"])
    return m

def train_cnn(h_img, h_comps, w_img, w_comps, input_size=48, max_per_class=400, epochs=10, batch=32):
    # é‡‡æ ·ï¼ˆå‡è¡¡ï¼‰
    H = h_comps[:max_per_class] if len(h_comps) > max_per_class else h_comps
    W = w_comps[:max_per_class] if len(w_comps) > max_per_class else w_comps
    n = min(len(H), len(W))
    if n < 10:
        return None, "å‚ç…§ã®ç²’å­ãŒå°‘ãªã™ãã¾ã™ï¼ˆå„10+æ¨å¥¨ï¼‰"

    xs, ys = [], []
    for i in range(n):
        xs.append(crop_patch(h_img, H[i], input_size)); ys.append(0)  # å¥åº·=0
        xs.append(crop_patch(w_img, W[i], input_size)); ys.append(1)  # ç™½æœªç†Ÿ=1
    X = np.asarray(xs, dtype=np.uint8)
    y = np.asarray(ys, dtype=np.float32)

    # æ‰“ä¹±
    idx = np.arange(len(y))
    np.random.shuffle(idx)
    X, y = X[idx], y[idx]

    model = build_tiny_cnn(input_size)
    h = model.fit(X, y, epochs=epochs, batch_size=batch, validation_split=0.15, verbose=0)
    va = float(h.history["val_accuracy"][-1])
    return model, f"CNNå­¦ç¿’å®Œäº†ï¼šValidation accuracy={va*100:.1f}%"

def cnn_predict(model, img_bgr, comps, input_size=48):
    probs = []
    for c in comps:
        patch = crop_patch(img_bgr, c, input_size)
        p = float(model.predict(patch[None, ...], verbose=0)[0][0])  # 0..1
        probs.append(p)
    return np.array(probs)




def draw_boxes(img_bgr, comps, flags=None):
    out = img_bgr.copy()
    for i,c in enumerate(comps):
        x1,y1,x2,y2 = c["bbox"]
        col = (106,161,255) if flags is None else ((91,91,255) if flags[i] else (53,211,57))
        cv2.rectangle(out, (x1,y1), (x2,y2), col, 2, cv2.LINE_AA)
    return out

#å›¾åƒåˆ†å‰²
h_img = w_img = t_img = None
h_comps = w_comps = t_comps = []

if healthy_file:
    h_img = read_bgr(healthy_file)
    _, h_comps = preprocess(h_img, bg_bright, th_offset, peak_min, peak_gap, min_area, max_area, open_iter)

if white_file:
    w_img = read_bgr(white_file)
    _, w_comps = preprocess(w_img, bg_bright, th_offset, peak_min, peak_gap, min_area, max_area, open_iter)

if target_file:
    t_img = read_bgr(target_file)
    _, t_comps = preprocess(t_img, bg_bright, th_offset, peak_min, peak_gap, min_area, max_area, open_iter)

#ç¬¬ä¸€è¡Œ
with c1:
    if h_img is not None:
        st.image(cv2.cvtColor(draw_boxes(h_img, h_comps), cv2.COLOR_BGR2RGB),
                 caption=f"å¥åº·ç²’ï¼š{len(h_comps)} ç²’", width=W_COL)

with c2:
    if w_img is not None:
        st.image(cv2.cvtColor(draw_boxes(w_img, w_comps), cv2.COLOR_BGR2RGB),
                 caption=f"ç™½æœªç†Ÿï¼š{len(w_comps)} ç²’", width=W_COL)

with c3:
    if t_img is not None:
        st.image(cv2.cvtColor(draw_boxes(t_img, t_comps), cv2.COLOR_BGR2RGB),
                 caption=f"åˆ¤å®šå¯¾è±¡ï¼š{len(t_comps)} ç²’ï¼ˆåˆ¤å®šå‰ï¼‰", width=W_COL)

#å­¦ç¿’
def learn_threshold(h_img, h_comps, w_img, w_comps):
    if not h_comps or not w_comps: return None
    hs = [whiteness_score(h_img, c) for c in h_comps]
    ws = [whiteness_score(w_img, c) for c in w_comps]
    return float((np.median(hs) + np.median(ws)) / 2.0)

def learn_ml(h_img, h_comps, w_img, w_comps):
    if (not SKLEARN_OK) or (LogisticRegression is None): return None
    if not h_comps or not w_comps: return None
    X, y = [], []
    for c in h_comps: X.append([whiteness_score(h_img, c), float(c["area"])]); y.append(0)
    for c in w_comps: X.append([whiteness_score(w_img, c), float(c["area"])]); y.append(1)
    if len(X) < 10: return None
    clf = LogisticRegression(max_iter=1000).fit(np.array(X), np.array(y))
    return clf

if learn_btn:
    if h_img is None or w_img is None:
        st.warning("â‘ å¥åº·ç²’ ã¨ â‘¡ç™½æœªç†Ÿ ã®å‚ç…§ç”»åƒã‚’å…ˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        # é˜ˆå€¼æ³•ï¼šå§‹ç»ˆå­¦ä¹ 
        th = learn_threshold(h_img, h_comps, w_img, w_comps)
        if th is None:
            st.warning("å‚ç…§ç”»åƒã‹ã‚‰æœ‰åŠ¹ãªç²’ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã€ä¸€æ ä¸€ç²’ã€ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state["threshold"] = float(th)
            msg = f"å­¦ç¿’å®Œäº†ï¼šã—ãã„å€¤ = {th:.4f}"

            # ML ä»»é€‰å…¶ä¸€
            if ml_mode == "Logistic":
                try:
                    from sklearn.linear_model import LogisticRegression
                    clf = learn_ml(h_img, h_comps, w_img, w_comps)
                    if clf is not None:
                        st.session_state["clf"] = clf
                        st.session_state.pop("cnn", None)
                        msg += " ï½œ ML=Logistic æœ‰åŠ¹"
                    else:
                        st.session_state.pop("clf", None)
                        msg += " ï½œ ML=Logistic ç„¡åŠ¹ï¼ˆå‚ç…§ç²’ãŒå°‘ãªã„ï¼‰"
                except Exception:
                    st.session_state.pop("clf", None)
                    msg += " ï½œ ML=Logistic ä½¿ç”¨ä¸å¯ï¼ˆç’°å¢ƒï¼‰"

            elif ml_mode == "CNN":
                model, note = train_cnn(h_img, h_comps, w_img, w_comps, input_size=48, epochs=10)
                if model is not None:
                    st.session_state["cnn"] = model
                    st.session_state.pop("clf", None)
                    msg += " ï½œ ML=CNN æœ‰åŠ¹"
                else:
                    st.session_state.pop("cnn", None)
                    msg += " ï½œ ML=CNN ç„¡åŠ¹ï¼ˆå‚ç…§ç²’ãŒå°‘ãªã„ï¼‰"
                st.info(note)

            else:  # ã—ãã„å€¤ã®ã¿
                st.session_state.pop("clf", None)
                st.session_state.pop("cnn", None)

            st.success(msg)


#åˆ¤å®š
if judge_btn:
    if t_img is None or not t_comps:
        st.warning("â‘¢åˆ¤å®šå¯¾è±¡ ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€ä¸€æ ä¸€ç²’ã€ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    elif "threshold" not in st.session_state:
        st.warning("å…ˆã« â‘ å­¦ç¿’ ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        th = float(st.session_state["threshold"])
        # ä¼˜å…ˆä½¿ç”¨ CNNï¼Œå…¶æ¬¡ Logisticï¼Œå¦åˆ™é˜ˆå€¼
        if "cnn" in st.session_state and st.session_state["cnn"] is not None and ml_mode == "CNN":
            probs = cnn_predict(st.session_state["cnn"], t_img, t_comps, input_size=48)
            is_white = probs >= 0.5
            used = "CNN"
        elif "clf" in st.session_state and st.session_state["clf"] is not None and ml_mode == "Logistic":
            scores = [whiteness_score(t_img, c) for c in t_comps]
            Xtest = np.stack([scores, [float(c["area"]) for c in t_comps]], axis=1)
            prob = st.session_state["clf"].predict_proba(Xtest)[:,1]
            is_white = prob >= 0.5
            used = "Logistic"
        else:
            scores = [whiteness_score(t_img, c) for c in t_comps]
            is_white = np.array([s >= th for s in scores])
            used = "ã—ãã„å€¤"

        total = len(is_white)
        n_white = int(np.sum(is_white))
        rate = (100.0 * n_white / total) if total else 0.0

        vis_big = cv2.cvtColor(
            draw_boxes(t_img, t_comps, flags=is_white.tolist()),
            cv2.COLOR_BGR2RGB
        )

        st.divider()
        st.subheader("åˆ¤å®šçµæœ")
        st.image(vis_big, width=900,
                 caption=f"çµæœï¼šç·æ•° {total}ï½œç™½æœªç†Ÿ {n_white}ï½œå‰²åˆ {rate:.1f}% ï½œ ML={used}")

        # å¯¼å‡º
        out_scores = (probs if used=="CNN" else (prob if used=="Logistic" else scores))
        df = pd.DataFrame({
            "id": np.arange(1, total+1, dtype=int),
            "area": [int(c['area']) for c in t_comps],
            "score": [float(s) for s in out_scores],
            "class": ["ç™½æœªç†Ÿ" if f else "æ•´ç²’" for f in is_white]
        })
        st.dataframe(df, use_container_width=True)
        st.download_button("CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                           data=df.to_csv(index=False).encode("utf-8-sig"),
                           file_name="result.csv", mime="text/csv")


#åˆæœŸ
if not (healthy_file or white_file or target_file):
    st.info("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å·¦å´ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ä¸€æ ä¸€ç²’ã€ã«èª¿æ•´ã€‚å®Œäº†å¾Œï¼šâ‘ å­¦ç¿’ â†’ â‘¡åˆ¤å®šã€‚")














